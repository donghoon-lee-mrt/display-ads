import streamlit as st
import os
import io
import re
import json
import time
import subprocess
import tempfile
import os
from pathlib import Path
from typing import List
from datetime import date, timedelta
import cv2
import numpy as np
import requests
import time

# ë¡œê¹… ì„¤ì •
import logging
from logging.handlers import RotatingFileHandler

def _safe_repr(obj, max_len: int = 2000):
    try:
        s = repr(obj)
        return s if len(s) <= max_len else s[:max_len] + "..."
    except Exception:
        return "<unrepr>"

def setup_logging():
    os.makedirs("logs", exist_ok=True)
    root_logger = logging.getLogger()
    if root_logger.handlers:
        return root_logger
    root_logger.setLevel(logging.DEBUG)
    fmt = logging.Formatter(
        fmt="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    file_handler = RotatingFileHandler(
        filename=os.path.join("logs", "app.log"),
        maxBytes=2 * 1024 * 1024,
        backupCount=3,
        encoding="utf-8",
    )
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(fmt)
    stream_handler = logging.StreamHandler()
    stream_handler.setLevel(logging.INFO)
    stream_handler.setFormatter(fmt)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(stream_handler)
    return root_logger

setup_logging()
logger = logging.getLogger(__name__)

def log_calls(level=logging.INFO):
    def _decorator(func):
        def _wrapper(*args, **kwargs):
            logger_local = logging.getLogger(func.__module__)
            logger_local.log(level, f"START {func.__name__} args=%s kwargs=%s", _safe_repr(args), _safe_repr(kwargs))
            _t0 = time.time()
            try:
                result = func(*args, **kwargs)
                _dt_ms = (time.time() - _t0) * 1000.0
                logger_local.log(level, f"END   {func.__name__} ok in {_dt_ms:.1f}ms")
                return result
            except Exception:
                _dt_ms = (time.time() - _t0) * 1000.0
                logger_local.exception(f"FAIL  {func.__name__} in {_dt_ms:.1f}ms")
                raise
        return _wrapper
    return _decorator

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¬ Marketing Video Generator",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
if 'GOOGLE_API_KEY' not in os.environ:
    os.environ['GOOGLE_API_KEY'] = 'Google api key'

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@log_calls()
@st.cache_resource
def init_gemini_client():
    # ì§€ì—° ë¡œë”©: google-genaiê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì–´ë„ ì•±ì´ ê¸°ë™ë˜ë„ë¡ í•¨
    try:
        from google import genai as _genai
        return _genai.Client()
    except Exception as e:
        raise e

try:
    client = init_gemini_client()
except Exception:
    client = None

# API ì„¤ì •
API_BASE = 'https://api3.myrealtrip.com/traveler-experiences/api/web/v2/traveler/products/{pid}/header'

@log_calls()
def find_first_image_url(obj):
    """ì¬ê·€ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ URL ì°¾ê¸°"""
    if isinstance(obj, dict):
        for v in obj.values():
            u = find_first_image_url(v)
            if u: return u
    elif isinstance(obj, list):
        for v in obj:
            u = find_first_image_url(v)
            if u: return u
    elif isinstance(obj, (str, bytes)):
        s = obj.decode() if isinstance(obj, bytes) else obj
        if re.search(r'\.(jpg|jpeg|png)(\?|$)', s, re.I):
            return s
    return None

@log_calls()
def analyze_images(pid):
    """APIì—ì„œ ì´ë¯¸ì§€ ë¶„ì„í•˜ì—¬ í›„ë³´êµ° ì„ ì •"""
    try:
        import requests
        hdr = requests.get(API_BASE.format(pid=pid), timeout=20)
        hdr.raise_for_status()
        data = hdr.json()['data']
        
        candidates = []
        images = data.get('images', [])
        
        # íƒ€ì…ë³„ ì¹´ìš´íŠ¸
        type_count = {}
        for img_info in images:
            img_type = img_info.get('type', 'UNKNOWN')
            type_count[img_type] = type_count.get(img_type, 0) + 1
        
        # NON_REVIEW ìš°ì„ , ê·¸ ë‹¤ìŒ REVIEW
        for priority_type in ['NON_REVIEW', 'REVIEW']:
            for img_info in images:
                url = img_info.get('url', '')
                img_type = img_info.get('type', '')
                
                if img_type != priority_type:
                    continue
                    
                # JPG/JPEGë§Œ, PNG/ì•„ì´ì½˜ ì œì™¸
                if not re.search(r'\.(jpg|jpeg)(\?|$)', url, re.I):
                    continue
                if 'icon' in url.lower():
                    continue
                    
                candidates.append({
                    'url': url,
                    'type': img_type,
                    'filename': url.split('/')[-1].split('?')[0],
                    'reviewId': img_info.get('reviewId', None)
                })
                
                if len(candidates) >= 8:  # 8ê°œë©´ ì¶©ë¶„
                    break
            
            if len(candidates) >= 8:
                break
        
        return candidates, type_count, len(images)
        
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return [], {}, 0

@log_calls()
def analyze_accommodation_images(pid: str, check_in: str, check_out: str, adult_count: int = 2, child_count: int = 0):
    """ìˆ™ì†Œ(Union) ì¶”ì²œ APIì—ì„œ ì´ë¯¸ì§€ í›„ë³´ ìˆ˜ì§‘

    ì°¸ê³  ì—”ë“œí¬ì¸íŠ¸:
    https://api3.myrealtrip.com/accommodations/v1/products/{pid}/front/recommendation?checkIn=YYYY-MM-DD&checkOut=YYYY-MM-DD&adultCount=N&childCount=M
    """
    try:
        import requests
        url = (
            "https://api3.myrealtrip.com/accommodations/v1/products/"
            f"{pid}/front/recommendation?checkIn={check_in}&checkOut={check_out}"
            f"&adultCount={adult_count}&childCount={child_count}"
        )
        resp = requests.get(url, timeout=20)
        resp.raise_for_status()
        data = resp.json()

        # sections[*].data[*].imageUrls.large / original ë“±ì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì§‘
        sections = data.get('data', {}).get('sections', [])
        candidates = []

        def _pick_image_url(image_urls: dict) -> str:
            if not isinstance(image_urls, dict):
                return ""
            for key in ["large", "original", "medium", "small", "thumb"]:
                url = image_urls.get(key)
                if isinstance(url, str) and re.search(r"\.(jpg|jpeg)(\?|$)", url, re.I):
                    return url
            # fallback: ì•„ë¬´ê±°ë‚˜ ë¬¸ìì—´
            for v in image_urls.values():
                if isinstance(v, str):
                    return v
            return ""

        total_items = 0
        for sec in sections:
            items = sec.get('data', []) if isinstance(sec, dict) else []
            total_items += len(items)
            for item in items:
                img_url = _pick_image_url(item.get('imageUrls', {}))
                if not img_url:
                    continue
                if 'icon' in img_url.lower():
                    continue
                candidates.append({
                    'url': img_url,
                    'type': 'ACCOM_RECO',
                    'filename': img_url.split('/')[-1].split('?')[0],
                    'reviewId': None
                })
                if len(candidates) >= 8:
                    break
            if len(candidates) >= 8:
                break

        # type_count ìœ ì‚¬ í¬ë§·ìœ¼ë¡œ ë°˜í™˜
        type_count = { 'ACCOM_RECO': len(candidates) }
        return candidates, type_count, total_items

    except Exception as e:
        st.error(f"ìˆ™ì†Œ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return [], {}, 0

@log_calls()
def analyze_bnb_images(product_id: str, start_date: str, end_date: str, adults: int = 1, children: int = 0):
    """í•œì¸ë¯¼ë°•(options) APIì—ì„œ ì˜µì…˜ ì¸ë„¤ì¼ ê¸°ë°˜ ì´ë¯¸ì§€ í›„ë³´ ìˆ˜ì§‘

    ì°¸ê³  ì—”ë“œí¬ì¸íŠ¸:
    https://api3.myrealtrip.com/product/products/{productId}/options?productId={productId}&startDate=YYYY-MM-DD&endDate=YYYY-MM-DD&adults=N&children=M&isReservable=false&roomTypes=
    """
    try:
        import requests
        base = "https://api3.myrealtrip.com/product/products"
        url = (
            f"{base}/{product_id}/options?productId={product_id}"
            f"&startDate={start_date}&endDate={end_date}"
            f"&adults={adults}&children={children}"
            f"&isReservable=false&roomTypes="
        )
        resp = requests.get(url, timeout=20)
        resp.raise_for_status()
        data = resp.json()

        # data ëŠ” ì˜µì…˜ ë°°ì—´. ê° item.thumbnailImageUrl ìˆ˜ì§‘
        items = data.get('data') if isinstance(data, dict) else data
        if items is None:
            items = []

        candidates = []
        for item in items:
            img_url = item.get('thumbnailImageUrl') if isinstance(item, dict) else None
            if not isinstance(img_url, str):
                continue
            if not re.search(r"\.(jpg|jpeg)(\?|$)", img_url, re.I):
                continue
            candidates.append({
                'url': img_url,
                'type': 'BNB_OPTION',
                'filename': img_url.split('/')[-1].split('?')[0],
                'reviewId': None
            })
            if len(candidates) >= 8:
                break

        type_count = { 'BNB_OPTION': len(candidates) }
        total_items = len(items)
        return candidates, type_count, total_items

    except Exception as e:
        st.error(f"í•œì¸ë¯¼ë°• API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return [], {}, 0

@log_calls()
def download_and_analyze_images(candidates, pid):
    """í›„ë³´ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° í•´ìƒë„ ë¶„ì„"""
    analyzed = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, cand in enumerate(candidates):
        try:
            status_text.text(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘... {i+1}/{len(candidates)}: {cand['filename']}")
            progress_bar.progress((i + 1) / len(candidates))
            
            import requests
            from PIL import Image
            img_bytes = requests.get(cand['url'], timeout=15).content
            img = Image.open(io.BytesIO(img_bytes)).convert('RGB')
            
            W, H = img.size
            aspect_ratio = H / W if W > 0 else 0
            is_portrait = aspect_ratio >= 1.2
            is_landscape = aspect_ratio <= 0.8
            
            # ì ìˆ˜ ê³„ì‚°: í•´ìƒë„ + NON_REVIEW ê°€ì‚°ì  + ì„¸ë¡œêµ¬ë„ ê°€ì‚°ì 
            base_score = W * H
            type_bonus = 2.0 if cand['type'] == 'NON_REVIEW' else 1.0
            orientation_bonus = 1.5 if is_portrait else 1.2 if is_landscape else 1.0
            
            analyzed.append({
                **cand,
                'image': img,
                'width': W,
                'height': H,
                'aspect_ratio': aspect_ratio,
                'is_portrait': is_portrait,
                'is_landscape': is_landscape,
                'pixels': W * H,
                'score': base_score * type_bonus * orientation_bonus
            })
            
        except Exception as e:
            st.warning(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {cand['filename']} - {e}")
    
    # ì ìˆ˜ìˆœ ì •ë ¬
    analyzed.sort(key=lambda x: x['score'], reverse=True)
    
    progress_bar.empty()
    status_text.empty()
    
    return analyzed


@log_calls()
def apply_text_overlay(video_path: str, text_settings: dict, product_id: str, ai_engine: str = "veo") -> str:
    """ë¹„ë””ì˜¤ì— í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì ìš©"""
    try:
        copy_text = text_settings.get('copy', '')
        if not copy_text:
            return video_path
        
        position = text_settings.get('position', 'top')
        # ìë™ ìŠ¤ì¼€ì¼(PlayResY ê¸°ì¤€ 1280) ì§€ì›
        auto_scale = bool(text_settings.get('auto_scale', False))
        font_scale_pct = text_settings.get('font_scale_pct', None)
        if auto_scale and isinstance(font_scale_pct, (int, float)):
            font_size = max(24, int(1280 * (float(font_scale_pct) / 100.0)))
        else:
            font_size = int(text_settings.get('font_size', 64))
        font_color = text_settings.get('font_color', 'white')
        border_width = int(text_settings.get('border_width', 3))
        if auto_scale:
            border_width = max(2, int(font_size * 0.06))
        bg_opacity = text_settings.get('bg_opacity', 0.4)
        
        # ì¶œë ¥ ê²½ë¡œ
        output_path = f"outputs/{product_id}/final_{ai_engine}.mp4"
        os.makedirs(f"outputs/{product_id}", exist_ok=True)
        
        # ASS ìë§‰ íŒŒì¼ ìƒì„±
        ass_file = f"outputs/{product_id}/overlay_{ai_engine}.ass"
        
        # ìœ„ì¹˜ë³„ ì„¤ì •
        if position == "top":
            alignment = 8  # ìƒë‹¨ ì¤‘ì•™
            margin_v = max(80, font_size * 2 if auto_scale else 120)
        elif position == "middle":
            alignment = 5  # ì¤‘ì•™
            margin_v = 0
        else:  # bottom
            alignment = 2  # í•˜ë‹¨ ì¤‘ì•™
            margin_v = max(80, font_size * 2 if auto_scale else 120)

        # ì¤„ë°”ê¿ˆì„ ASS ìë§‰ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (f-string ë‚´ì—ì„œ ë°±ìŠ¬ë˜ì‹œ ì‚¬ìš© ë¶ˆê°€)
        formatted_copy = copy_text.replace('\n', '\\N')

        # ASS ìë§‰ ë‚´ìš©
        ass_content = f"""[Script Info]
; Script generated by Marketing Video Generator
ScriptType: v4.00+
PlayResX: 720
PlayResY: 1280

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,AppleSDGothicNeo,{font_size},&H00FFFFFF,&H000000FF,&H00000000,&H66000000,0,0,0,0,100,100,0,0,1,{border_width},0,{alignment},60,60,{margin_v},1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:10.00,Default,,0,0,0,,{formatted_copy}"""
        
        # ASS íŒŒì¼ ì €ì¥
        with open(ass_file, 'w', encoding='utf-8') as f:
            f.write(ass_content)
        
        # FFmpeg ëª…ë ¹ì–´ë¡œ ìë§‰ í•©ì„±
        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-vf', f"subtitles={ass_file}",
            '-c:a', 'copy',
            '-preset', 'fast',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode != 0:
            raise Exception(f"FFmpeg ì˜¤ë¥˜: {result.stderr}")
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(ass_file):
            try:
                os.unlink(ass_file)
            except PermissionError:
                pass
        
        return output_path
        
    except Exception as e:
        logger.exception(f"í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì ìš© ì‹¤íŒ¨: {e}")
        return video_path


@log_calls()
def extract_copy_from_api(pid: str, product_type: str = "travel"):
    """ìƒí’ˆ ìœ í˜•ë³„ ë§ˆì¼€íŒ… ì¹´í”¼ ì¶”ì¶œ (ì—¬í–‰/ìˆ™ì†Œ/í•´ì™¸í˜¸í…”/í•œì¸ë¯¼ë°•)

    - travel: traveler-experiences header API ì‚¬ìš©
    - accommodation/overseas_hotel: ì¶”ì²œ APIì—ì„œ ê·¼ì‚¬ íƒ€ì´í‹€ ì‹œë„, ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¬¸êµ¬
    - bnb: options APIì—ì„œ ì²« ì˜µì…˜ íƒ€ì´í‹€/ê°€ê²©ìœ¼ë¡œ ì¹´í”¼ êµ¬ì„±
    """
    try:
        import requests
        if product_type == "travel":
            hdr = requests.get(API_BASE.format(pid=pid), timeout=20)
            data = hdr.json().get('data', {})
            title = (data.get('title') or '').strip()
            price_info = data.get('ctaButton', {}).get('price', {})
            sale_price = price_info.get('salePrice', '')
        copy_lines = []
        if title:
            copy_lines.append(title)
        if sale_price:
            copy_lines.append(f'ì§€ê¸ˆ ì˜ˆì•½ Â· {sale_price}')
            return '\n'.join(copy_lines) if copy_lines else 'ì§€ê¸ˆ ì˜ˆì•½í•˜ê³  í˜œíƒ ë°›ê¸°'

        if product_type in ("accommodation", "overseas_hotel"):
            today_ = date.today()
            ci = (today_ + timedelta(days=7)).strftime('%Y-%m-%d')
            co = (today_ + timedelta(days=8)).strftime('%Y-%m-%d')
            url = (
                "https://api3.myrealtrip.com/accommodations/v1/products/"
                f"{pid}/front/recommendation?checkIn={ci}&checkOut={co}&adultCount=2&childCount=0"
            )
            r = requests.get(url, timeout=20)
            js = r.json()
            sections = js.get('data', {}).get('sections', [])
            # ì²« ì•„ì´í…œì˜ íƒ€ì´í‹€ì„ ì‚¬ìš© (ì—†ìœ¼ë©´ ê¸°ë³¸)
            for sec in sections:
                items = sec.get('data', []) if isinstance(sec, dict) else []
                if items:
                    title = (items[0].get('title') or '').strip()
                    if title:
                        return title
                    break
            return 'ì§€ê¸ˆ ì˜ˆì•½í•˜ê³  í˜œíƒ ë°›ê¸°'

        if product_type == "bnb":
            today_ = date.today()
            start_date = (today_ + timedelta(days=7)).strftime('%Y-%m-%d')
            end_date = (today_ + timedelta(days=8)).strftime('%Y-%m-%d')
            url = (
                f"https://api3.myrealtrip.com/product/products/{pid}/options?productId={pid}"
                f"&startDate={start_date}&endDate={end_date}&adults=2&children=0&isReservable=false&roomTypes="
            )
            r = requests.get(url, timeout=20)
            js = r.json()
            items = js.get('data') if isinstance(js, dict) else js
            items = items or []
            if items:
                first = items[0]
                title = (first.get('title') or '').strip()
                sale = (first.get('priceInfo', {}) or {}).get('salePrice', {})
                amount = sale.get('amount')
                suffix = sale.get('suffix') or ''
                price_text = None
                if isinstance(amount, (int, float)):
                    price_text = f"{int(amount):,}{suffix}"
                elif sale:
                    # fallback textual sale price
                    price_text = f"{sale}" if isinstance(sale, str) else None
                copy_lines = []
                if title:
                    copy_lines.append(title)
                if price_text:
                    copy_lines.append(f"ì§€ê¸ˆ ì˜ˆì•½ Â· {price_text}")
                return '\n'.join(copy_lines) if copy_lines else 'ì§€ê¸ˆ ì˜ˆì•½í•˜ê³  í˜œíƒ ë°›ê¸°'

        # ê¸°íƒ€: ê¸°ë³¸ ë¬¸êµ¬
        return 'ì§€ê¸ˆ ì˜ˆì•½í•˜ê³  í˜œíƒ ë°›ê¸°'
    except Exception as e:
        st.error(f"ì¹´í”¼ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return "ì§€ê¸ˆ ì˜ˆì•½í•˜ê³  í˜œíƒ ë°›ê¸°"

@log_calls()
def create_resized_preview(image, target_width=1080, target_height=1920):
    """ë¦¬ì‚¬ì´ì¦ˆ ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
    from PIL import Image
    W, H = image.size
    scale = max(target_width/W, target_height/H)
    new = image.resize((int(W*scale), int(H*scale)), Image.LANCZOS)
    nw, nh = new.size
    left, top = (nw-target_width)//2, (nh-target_height)//2
    cover = new.crop((left, top, left+target_width, top+target_height))
    return cover

@log_calls()
def create_text_overlay_preview(image, text, font_size=64, font_color="white", 
                               border_width=3, border_color="black", 
                               position="top", bg_opacity=0.4):
    """í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
    from PIL import Image, ImageDraw, ImageFont
    preview = image.copy()
    draw = ImageDraw.Draw(preview)
    
    # í°íŠ¸ ë¡œë“œ ì‹œë„
    try:
        font = ImageFont.truetype('/System/Library/Fonts/AppleSDGothicNeo.ttc', font_size)
    except:
        font = ImageFont.load_default()
    
    # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
    text_lines = text.split('\n')
    line_height = font_size + 8
    total_height = len(text_lines) * line_height
    
    # ìœ„ì¹˜ ê³„ì‚°
    img_w, img_h = preview.size
    if position == "top":
        y_start = 80
    elif position == "middle":
        y_start = (img_h - total_height) // 2
    else:  # bottom
        y_start = img_h - total_height - 80
    
    # ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    max_width = max([draw.textlength(line, font=font) for line in text_lines])
    box_padding = 20
    box_x1 = (img_w - max_width) // 2 - box_padding
    box_y1 = y_start - box_padding
    box_x2 = (img_w + max_width) // 2 + box_padding
    box_y2 = y_start + total_height + box_padding
    
    # ë°˜íˆ¬ëª… ë°°ê²½
    overlay = Image.new('RGBA', preview.size, (0, 0, 0, 0))
    overlay_draw = ImageDraw.Draw(overlay)
    overlay_draw.rectangle([box_x1, box_y1, box_x2, box_y2], 
                          fill=(0, 0, 0, int(255 * bg_opacity)))
    preview = Image.alpha_composite(preview.convert('RGBA'), overlay).convert('RGB')
    draw = ImageDraw.Draw(preview)
    
    # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
    for i, line in enumerate(text_lines):
        y = y_start + i * line_height
        text_width = draw.textlength(line, font=font)
        x = (img_w - text_width) // 2
        
        # í…Œë‘ë¦¬
        for dx in [-border_width, 0, border_width]:
            for dy in [-border_width, 0, border_width]:
                if dx != 0 or dy != 0:
                    draw.text((x+dx, y+dy), line, font=font, fill=border_color)
        
        # ë©”ì¸ í…ìŠ¤íŠ¸
        draw.text((x, y), line, font=font, fill=font_color)
    
    return preview

@log_calls()
def generate_local_simulation_video(image, output_path: str, duration: int = 5, fps: int = 30):
    """ì„ íƒ ì´ë¯¸ì§€ë¡œ ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜ ì˜ìƒ ìƒì„±(í¬ë ˆë”§ ì†Œì§„ ì—†ìŒ)"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    base = create_resized_preview(image, target_width=1080, target_height=1920)
    width, height = 1080, 1920
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(output_path, fourcc, float(fps), (width, height))
    total_frames = max(1, int(duration * fps))
    base_np = cv2.cvtColor(np.array(base), cv2.COLOR_RGB2BGR)
    # ì•„ì£¼ ì•½í•œ ì¤Œì¸ ëª¨ì…˜
    for i in range(total_frames):
        t = i / max(1, total_frames - 1)
        scale = 1.0 + 0.04 * t
        sw, sh = int(width * scale), int(height * scale)
        frame = cv2.resize(base_np, (sw, sh), interpolation=cv2.INTER_LANCZOS4)
        x1 = (sw - width) // 2
        y1 = (sh - height) // 2
        crop = frame[y1:y1+height, x1:x1+width]
        writer.write(crop)
    writer.release()
    return output_path

@log_calls()
def safe_unlink(path: str, retries: int = 3, delay: float = 0.2) -> None:
    """Windowsì—ì„œ íŒŒì¼ í•¸ë“¤ ì ìœ ë¡œ ì‚­ì œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„."""
    for _ in range(retries):
        try:
            if os.path.exists(path):
                os.unlink(path)
            return
        except PermissionError:
            time.sleep(delay)
    # ë§ˆì§€ë§‰ ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•˜ë©´ ë¬´ì‹œ
    try:
        if os.path.exists(path):
            os.unlink(path)
    except Exception:
        pass


@log_calls()
@st.cache_data(ttl=300)
def get_higgs_motions(api_key: str = None, api_secret: str = None) -> List[dict]:
    """Higgsfield ëª¨ì…˜ ëª©ë¡ì„ APIë¡œ ì¡°íšŒ (5ë¶„ ìºì‹œ). UI ì…ë ¥ê°’ì´ ìˆìœ¼ë©´ ìš°ì„ ."""
    try:
        api_key_eff = (api_key or os.getenv("HIGGS_API_KEY", "")).strip()
        api_secret_eff = (api_secret or os.getenv("HIGGS_SECRET", "")).strip()
        if not api_key_eff:
            return []
        url = "https://platform.higgsfield.ai/v1/motions"
        headers = {"hf-api-key": api_key_eff}
        if api_secret_eff:
            headers["hf-secret"] = api_secret_eff
        resp = requests.get(url, headers=headers, timeout=15)
        if resp.status_code != 200:
            return []
        data = resp.json()
        if isinstance(data, list):
            return data
        return []
    except Exception:
        return []

@log_calls()
def resolve_image_url(selected_item: dict) -> str:
    """ì„ íƒëœ í•­ëª©ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ URLì„ ìµœëŒ€í•œ ë³µêµ¬í•œë‹¤."""
    try:
        # 1) ì§ì ‘ ë³´ìœ í•œ url ìš°ì„ 
        u = selected_item.get('url')
        if isinstance(u, str) and u.startswith('http'):
            return u
        # 2) ì„¸ì…˜ candidatesì—ì„œ filename ë§¤ì¹­ìœ¼ë¡œ íƒìƒ‰
        candidates = st.session_state.get('candidates', [])
        sel_fname = selected_item.get('filename')
        if sel_fname:
            for c in candidates:
                if c.get('filename') == sel_fname:
                    cu = c.get('url')
                    if isinstance(cu, str) and cu.startswith('http'):
                        return cu
        # 3) ë°±ì—… í‚¤ë“¤ íƒìƒ‰
        for key in ('source_url', 'original_url', 'image_url'):
            uu = selected_item.get(key)
            if isinstance(uu, str) and uu.startswith('http'):
                return uu
    except Exception:
        pass
    return ''

@log_calls()
def generate_video_with_veo(image, prompt, progress_callback=None):
    """Veoë¡œ ì˜ìƒ ìƒì„±"""
    try:
        global client
        if client is None:
            try:
                client = init_gemini_client()
            except Exception as e:
                raise Exception(f"Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        if progress_callback:
            progress_callback("Veo ì˜ìƒ ìƒì„± ì‹œì‘...")
        
        # ì§€ì—° ì„í¬íŠ¸ (types)
        from google.genai import types as _types

        op = client.models.generate_videos(
            model='veo-3.0-fast-generate-001',
            prompt=prompt,
            image=image,
            config=_types.GenerateVideosConfig(
                aspect_ratio='9:16', 
                resolution='720p', 
                person_generation='allow_adult'
            ),
        )
        
        # í´ë§
        waited = 0
        max_wait = 600  # 10ë¶„ ìµœëŒ€ ëŒ€ê¸°
        while not op.done and waited < max_wait:
            if progress_callback:
                progress_callback(f"Veo ìƒì„± ì¤‘... ({waited}s)")
            time.sleep(30)
            waited += 30
            try:
                op = client.operations.get(op)
            except Exception as e:
                if progress_callback:
                    progress_callback(f"í´ë§ ì˜¤ë¥˜: {e}")
                break
        
        if not op.done:
            raise Exception(f"íƒ€ì„ì•„ì›ƒ ({max_wait}ì´ˆ)")
        
        # ê²°ê³¼ í™•ì¸
        if (hasattr(op, 'response') and op.response and 
            hasattr(op.response, 'generated_videos') and op.response.generated_videos and
            len(op.response.generated_videos) > 0):
            return op.response.generated_videos[0]
        else:
            raise Exception("ìƒì„±ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        raise Exception(f"ì˜ìƒ ìƒì„± ì˜¤ë¥˜: {e}")

# ë©”ì¸ UI
def main():
    logger.info("Streamlit main loaded. session_keys=%s", list(st.session_state.keys()))
    st.title("ğŸ¬ Marketing Video Generator")
    st.markdown("**MyRealTrip ìƒí’ˆìœ¼ë¡œ ìë™ ë§ˆì¼€íŒ… ì˜ìƒ ìƒì„±**")
    
    # (í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì œê±°ë¨)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ìƒí’ˆ ID ì…ë ¥ (ì„¸ì…˜ ìƒíƒœì— ë”°ë¼ ê¸°ë³¸ê°’ ì„¤ì •)
        default_product_id = st.session_state.get('product_id', "4454757")
        product_id = st.text_input(
            "ìƒí’ˆ ID ì…ë ¥", 
            value=default_product_id,
            help="MyRealTrip ìƒí’ˆ IDë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 4454757)",
            key="product_id_input"
        )
        
        # ì§ì ‘ ì…ë ¥ëœ ìƒí’ˆ IDë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
        if product_id and product_id.strip():
            # ì„¸ì…˜ì˜ product_idë¥¼ ì§ì ‘ ì…ë ¥ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            if 'product_id' in st.session_state and st.session_state.product_id != product_id:
                # ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”
                if 'analyzed_images' in st.session_state:
                    del st.session_state['analyzed_images']
                if 'marketing_copy' in st.session_state:
                    del st.session_state['marketing_copy']
                st.success(f"âœ… ìƒí’ˆ IDë¥¼ {product_id}ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤!")
            
            st.session_state.product_id = product_id
        
        # ìƒí’ˆ ìœ í˜• ì„ íƒ
        product_type = st.selectbox(
            "ìƒí’ˆ ìœ í˜•",
            options=["travel", "accommodation", "overseas_hotel", "bnb"],
            index=0,
            format_func=lambda x: {"travel": "ğŸ§­ ì—¬í–‰ìƒí’ˆ", "accommodation": "ğŸ¨ ìˆ™ì†Œ(êµ­ë‚´)", "overseas_hotel": "ğŸŒ í•´ì™¸í˜¸í…”", "bnb": "ğŸ  í•œì¸ë¯¼ë°•"}[x]
        )

        # ë¹„ì—¬í–‰ ìƒí’ˆìš© ì²´í¬ì¸/ì²´í¬ì•„ì›ƒ/ì¸ì› ì…ë ¥ UI ì œê±° (ê¸°ë³¸ê°’ ë‚´ë¶€ ì ìš©)
        
        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", help="ìƒí’ˆ ì •ë³´ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤"):
            if 'analyzed_images' in st.session_state:
                del st.session_state['analyzed_images']
            if 'marketing_copy' in st.session_state:
                del st.session_state['marketing_copy']
            if 'last_product_id' in st.session_state:
                del st.session_state['last_product_id']
            logger.info("Refresh requested. Cleared cached states.")
            st.rerun()
        
        # ì˜ˆì‹œ ìƒí’ˆë“¤
        st.markdown("**ğŸ“‹ ì˜ˆì‹œ ìƒí’ˆë“¤:**")
        example_products = {
            "4454757": "ìƒí•˜ì´ ë””ì¦ˆë‹ˆëœë“œ",
            "3147866": "ëŸ°ë˜ ë‚´ì…”ë„ê°¤ëŸ¬ë¦¬", 
            "3149960": "í¬íŠ¸ìŠ¤í…ŒíŒ íˆ¬ì–´",
            "3442342": "ìƒˆë¡œìš´ ìƒí’ˆ"
        }
        
        for pid, name in example_products.items():
            if st.button(f"{name} ({pid})", key=f"example_{pid}"):
                # ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”
                if 'analyzed_images' in st.session_state:
                    del st.session_state['analyzed_images']
                if 'marketing_copy' in st.session_state:
                    del st.session_state['marketing_copy']
                if 'last_product_id' in st.session_state:
                    del st.session_state['last_product_id']
                
                # text_inputì„ ê°•ì œë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ í‚¤ë¥¼ ì‚­ì œ
                if 'product_id_input' in st.session_state:
                    del st.session_state['product_id_input']
                
                # ìƒˆë¡œìš´ ìƒí’ˆ ID ì„¤ì •
                st.session_state.product_id = pid
                logger.info("Example product selected. pid=%s, name=%s", pid, name)
                st.success(f"âœ… ì˜ˆì‹œ ìƒí’ˆ '{name} ({pid})'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        
        # ìµœì¢… product_idëŠ” ì´ë¯¸ session_stateì— ì„¤ì •ë¨
        final_product_id = st.session_state.get('product_id', product_id)
    
    # ë©”ì¸ ì»¨í…ì¸ 
    if final_product_id:
        st.markdown(f"### ğŸ“¦ ìƒí’ˆ ID: `{final_product_id}`")
        product_id = final_product_id  # ì´í›„ ì½”ë“œì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ í†µì¼
        
        # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„
        if st.button("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘", type="primary"):
            logger.info("Image analysis requested. pid=%s, type=%s", product_id, product_type)
            with st.spinner("ì´ë¯¸ì§€ í›„ë³´êµ° ë¶„ì„ ì¤‘..."):
                if product_type in ("accommodation", "overseas_hotel"):
                    # ë‚´ë¶€ ê¸°ë³¸ê°’ ì‚¬ìš© (ì²´í¬ì¸+7ì¼, 1ë°•, ì„±ì¸2, ì•„ë™0)
                    today_ = date.today()
                    ci_str = (today_ + timedelta(days=7)).strftime('%Y-%m-%d')
                    co_str = (today_ + timedelta(days=8)).strftime('%Y-%m-%d')
                    adult_cnt = 2
                    child_cnt = 0
                    candidates, type_count, total_images = analyze_accommodation_images(
                        product_id, ci_str, co_str, adult_cnt, child_cnt
                    )
                elif product_type == "bnb":
                    today_ = date.today()
                    ci_str = (today_ + timedelta(days=7)).strftime('%Y-%m-%d')
                    co_str = (today_ + timedelta(days=8)).strftime('%Y-%m-%d')
                    adult_cnt = 2
                    child_cnt = 0
                    candidates, type_count, total_images = analyze_bnb_images(
                        product_id, ci_str, co_str, adult_cnt, child_cnt
                    )
                else:
                    candidates, type_count, total_images = analyze_images(product_id)
                
                if candidates:
                    logger.info("Image candidates discovered. total_images=%s, candidates=%s, type_count=%s", total_images, len(candidates), type_count)
                    st.success(f"âœ… ì´ {total_images}ì¥ ì¤‘ {len(candidates)}ê°œ í›„ë³´ ë°œê²¬!")
                    st.info(f"ğŸ“Š ì´ë¯¸ì§€ íƒ€ì…: {type_count}")
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.candidates = candidates
                    st.session_state.product_id_current = product_id
                    
                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
                    analyzed = download_and_analyze_images(candidates, product_id)
                    st.session_state.analyzed_images = analyzed
                    
                else:
                    logger.warning("No suitable images found. pid=%s, type=%s", product_id, product_type)
                    st.error("âŒ ì í•©í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 2ë‹¨ê³„: ì´ë¯¸ì§€ ì„ íƒ
        if 'analyzed_images' in st.session_state and st.session_state.get('product_id_current') == product_id:
            st.markdown("### ğŸ–¼ï¸ ì´ë¯¸ì§€ ì„ íƒ")
            
            analyzed = st.session_state.analyzed_images
            # REVIEW íƒ€ì… ì´ë¯¸ì§€ëŠ” UIì—ì„œ ì¶”ê°€ í•„í„°ë§í•˜ì—¬ ì œì™¸
            try:
                analyzed = [it for it in analyzed if str(it.get('type', '')).upper() != 'REVIEW']
            except Exception:
                pass
            if not analyzed:
                st.warning("í‘œì‹œí•  ìˆ˜ ìˆëŠ” NON_REVIEW(ë˜ëŠ” ë¹„-ë¦¬ë·°) ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒí’ˆ ìœ í˜•/IDë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                return
            
            # ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ í‘œì‹œ
            cols = st.columns(4)
            selected_image = None
            
            for i, item in enumerate(analyzed[:8]):  # ìµœëŒ€ 8ê°œ
                with cols[i % 4]:
                    # ì´ë¯¸ì§€ í‘œì‹œ
                    st.image(item['image'], caption=f"#{i+1}", width="stretch")
                    
                    # ì •ë³´ í‘œì‹œ
                    orientation = "ì„¸ë¡œ" if item['is_portrait'] else "ê°€ë¡œ" if item['is_landscape'] else "ì •ë°©"
                    st.caption(f"{item['width']}x{item['height']} ({orientation})")
                    
                    # íƒ€ì… í‘œì‹œ
                    type_color = "ğŸ”µ" if item['type'] == 'NON_REVIEW' else "ğŸŸ¢"
                    st.caption(f"{type_color} {item['type']}")
                    
                    # ì„ íƒ ë²„íŠ¼
                    if st.button(f"ì„ íƒ", key=f"select_{i}"):
                        st.session_state.selected_image = item
                        logger.info("Image #%s selected. size=%sx%s type=%s", i+1, item['width'], item['height'], item['type'])
                        st.success(f"âœ… ì´ë¯¸ì§€ #{i+1} ì„ íƒë¨!")
            
            # 3ë‹¨ê³„: ë¯¸ë¦¬ë³´ê¸° & ì»¤ìŠ¤í„°ë§ˆì´ì§•
            if 'selected_image' in st.session_state:
                st.markdown("### ğŸ¨ ë¯¸ë¦¬ë³´ê¸° & ì»¤ìŠ¤í„°ë§ˆì´ì§•")
                
                selected = st.session_state.selected_image
                
                # ë§ˆì¼€íŒ… ì¹´í”¼ ì¶”ì¶œ (ìƒí’ˆ ìœ í˜•ë³„)
                logger.info("Extracting marketing copy. pid=%s, type=%s", product_id, product_type)
                copy_text = extract_copy_from_api(product_id, product_type)
                
                col1, col2, col3 = st.columns([1, 1, 1])
                
                with col1:
                    st.markdown("#### ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€")
                    st.image(selected['image'], caption="ì„ íƒëœ ì›ë³¸", width="stretch")
                    st.caption(f"{selected['width']}x{selected['height']} ({selected['type']})")
                
                with col2:
                    st.markdown("#### ğŸ“ ë¦¬ì‚¬ì´ì¦ˆ ë¯¸ë¦¬ë³´ê¸°")
                    resized_preview = create_resized_preview(selected['image'])
                    st.image(resized_preview, caption="1080x1920 í¬ë¡­ ê²°ê³¼", width="stretch")
                    st.caption("9:16 ë¹„ìœ¨ë¡œ ìë™ í¬ë¡­ë¨")
                
                with col3:
                    st.markdown("#### ğŸ¨ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´")
                    st.info("í˜„ì¬ ë²„ì „ì—ì„œëŠ” í…ìŠ¤íŠ¸ ì„¤ì • ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                
                # 4ë‹¨ê³„: ì˜ìƒ ìƒì„± ì„¤ì •
                st.markdown("### ğŸ¬ ì˜ìƒ ìƒì„± ì„¤ì •")
                
                col_prompt1, col_prompt2 = st.columns([2, 1])
                
                with col_prompt1:
                    # í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•
                    prompt_template = st.text_area(
                        "ì˜ìƒ ìƒì„± í”„ë¡¬í”„íŠ¸",
                        value=(
                            "Create a cinematic 9:16 travel video from this image. "
                            "Add gentle camera movement with slow push-in and subtle pan. "
                            "Include environmental motion like breeze, sparkles, or natural movement. "
                            "If people are visible, show them walking naturally. "
                            "Maintain the original colors and atmosphere. Vertical format, high quality."
                        ),
                        height=120
                    )
                
                with col_prompt2:
                    st.markdown("**ğŸ¯ ìƒì„± ì˜µì…˜**")
                    dry_run_flow = st.checkbox("í¬ë ˆë”§ ì†Œì§„ ì—†ì´ ì˜ìƒ ë¡œì§ë§Œ ê²€í†  (ë“œë¼ì´ëŸ°)", value=True, help="ì‹¤ì œ AI í˜¸ì¶œ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ ì˜ìƒìœ¼ë¡œ ì „ì²´ íë¦„ì„ ê²€í† í•©ë‹ˆë‹¤.")
                    image_source = st.radio("ì˜ìƒ ìƒì„±ì— ì‚¬ìš©í•  ì´ë¯¸ì§€", options=["resized", "original"], index=0, format_func=lambda x: {"resized": "ğŸ“ ë¦¬ì‚¬ì´ì¦ˆ(1080x1920)", "original": "ğŸ–¼ï¸ ì›ë³¸ ì´ë¯¸ì§€"}[x])
                    
                    # AI ì—”ì§„ ì„ íƒ
                    ai_engine = st.selectbox(
                        "ğŸ¤– AI ì—”ì§„",
                        options=["higgs"],
                        index=0,
                        format_func=lambda x: {"higgs": "ğŸ§² HiggsField"}[x],
                        help="HiggsField ì—”ì§„ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤"
                    )
                    
                    if ai_engine == "gemini_veo":
                        # Veo ëª¨ë¸ ì„ íƒ
                        model_choice = st.selectbox(
                            "Veo ëª¨ë¸",
                            options=["veo-3.0-fast-generate-001", "veo-3.0-generate-001"],
                            index=0,
                            format_func=lambda x: {"veo-3.0-fast-generate-001": "âš¡ Fast (ë¹ ë¦„)", 
                                                  "veo-3.0-generate-001": "ğŸ¨ Standard (ê³ í’ˆì§ˆ)"}[x]
                        )
                        
                        # í•´ìƒë„ ì„ íƒ
                        resolution = st.selectbox(
                            "í•´ìƒë„",
                            options=["720p", "1080p"],
                            index=0
                        )
                    
                    elif ai_engine == "runway":
                        # Runway ëª¨ë¸ ì„ íƒ
                        runway_model = st.selectbox(
                            "Runway ëª¨ë¸",
                            options=["gen3a_turbo", "veo3"],
                            index=0,
                            format_func=lambda x: {
                                "gen3a_turbo": "ğŸš€ Gen3a Turbo (ë¹ ë¦„, ì €ë ´ ~150í¬ë ˆë”§)", 
                                "veo3": "ğŸ”® VEO3 (ê³ í’ˆì§ˆ, ë¹„ì‹¸ ~320í¬ë ˆë”§)"
                            }[x],
                            help="Gen3a Turbo: ë¹ ë¥´ê³  ì €ë ´ vs VEO3: ëŠë¦¬ì§€ë§Œ ê³ í’ˆì§ˆ"
                        )
                        
                        # Veo ì „ìš© ì„¤ì •ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                        
                    elif ai_engine == "runway_ai":
                        # Runway AI ì „ìš© ì˜µì…˜ë“¤
                        st.markdown("**ğŸ¬ Runway AI ì„¤ì •**")
                    elif ai_engine == "higgs":
                        st.markdown("**ğŸ§² HiggsField ì„¤ì •**")
                        # í‚¤ ì…ë ¥ UI (ì„¸ì…˜ì— ì €ì¥)
                        st.markdown("í‚¤ ì…ë ¥ (UI ê°’ì´ í™˜ê²½ë³€ìˆ˜ë³´ë‹¤ ìš°ì„  ì ìš©)")
                        st.session_state.HIGGS_API_KEY = st.text_input("HIGGS_API_KEY", value=st.session_state.get("HIGGS_API_KEY", ""), type="password")
                        st.session_state.HIGGS_SECRET = st.text_input("HIGGS_SECRET", value=st.session_state.get("HIGGS_SECRET", ""), type="password")

                        # ê¸°ë³¸ê°’ë§Œ ë…¸ì¶œ. ê³ ê¸‰ ì˜µì…˜ì€ API ëª…ì„¸ í™•ì • í›„ ì¶”ê°€
                        higgs_model = st.text_input("ëª¨ë¸ ID", value="dop-turbo")
                        st.caption("ëª¨ë¸/ì˜µì…˜ì€ ì„ì‹œê°’ì…ë‹ˆë‹¤. API ëª…ì„¸ ìˆ˜ì‹  í›„ ì—…ë°ì´íŠ¸")
                        # ì‹¤ì‹œê°„ ëª¨ì…˜ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (UI í‚¤ ìš°ì„ )
                        motions = get_higgs_motions(
                            api_key=st.session_state.get("HIGGS_API_KEY", None),
                            api_secret=st.session_state.get("HIGGS_SECRET", None)
                        )
                        motion_names = [m.get('name') for m in motions if m.get('name')]
                        default_names = motion_names[:2] if motion_names else []
                        higgs_motions = st.multiselect(
                            "ëª¨ì…˜ ì„ íƒ (Higgs Motions)",
                            options=motion_names if motion_names else ["push_in", "clouds"],
                            default=default_names if default_names else ["push_in", "clouds"],
                            help="Higgsfield ì œê³µ ëª¨ì…˜ ëª©ë¡ì„ ì‹¤ì‹œê°„ ì¡°íšŒí•˜ì—¬ ì„ íƒí•©ë‹ˆë‹¤."
                        )
                        
                        video_duration = st.slider(
                            "ë¹„ë””ì˜¤ ê¸¸ì´ (ì´ˆ)",
                            min_value=2,
                            max_value=10,
                            value=5,
                            help="ìƒì„±í•  ë¹„ë””ì˜¤ì˜ ê¸¸ì´ë¥¼ ì„¤ì •í•˜ì„¸ìš”"
                        )
                        
                        motion_strength = st.slider(
                            "ì›€ì§ì„ ê°•ë„",
                            min_value=0.0,
                            max_value=1.0,
                            value=0.5,
                            step=0.1,
                            help="0.0: ìµœì†Œ ì›€ì§ì„, 1.0: ìµœëŒ€ ì›€ì§ì„"
                        )
                        
                        use_seed = st.checkbox("ì‹œë“œê°’ ì‚¬ìš© (ì¬í˜„ì„±)", value=False)
                        seed_value = None
                        if use_seed:
                            seed_value = st.number_input(
                                "ì‹œë“œê°’",
                                min_value=0,
                                max_value=999999,
                                value=42,
                                help="ê°™ì€ ì‹œë“œê°’ìœ¼ë¡œ ë™ì¼í•œ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥"
                            )

                        # (Higgs ì „ìš©: Runway ê´€ë ¨ ì˜µì…˜ ìˆ¨ê¹€)
                
                # ì˜ìƒ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì„¹ì…˜
                st.markdown("### ğŸ¥ ì˜ìƒ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•")
                
                col_camera, col_motion, col_style = st.columns(3)
                
                with col_camera:
                    st.markdown("**ğŸ“¹ ì¹´ë©”ë¼ ì›€ì§ì„**")
                    
                    camera_movement = st.selectbox(
                        "ì¹´ë©”ë¼ ë™ì‘",
                        options=["push_in", "pull_out", "pan_left", "pan_right", "tilt_up", "tilt_down", "static", "orbit"],
                        index=0,
                        format_func=lambda x: {
                            "push_in": "ğŸ“ Push-in (ì¤Œì¸)",
                            "pull_out": "ğŸ“¤ Pull-out (ì¤Œì•„ì›ƒ)", 
                            "pan_left": "â¬…ï¸ Pan Left (ì¢Œì¸¡ ì´ë™)",
                            "pan_right": "â¡ï¸ Pan Right (ìš°ì¸¡ ì´ë™)",
                            "tilt_up": "â¬†ï¸ Tilt Up (ìœ„ë¡œ í‹¸íŠ¸)",
                            "tilt_down": "â¬‡ï¸ Tilt Down (ì•„ë˜ë¡œ í‹¸íŠ¸)",
                            "static": "ğŸ”’ Static (ê³ ì •)",
                            "orbit": "ğŸ”„ Orbit (ì›í˜• ì´ë™)"
                        }[x],
                        help="ì¹´ë©”ë¼ê°€ ì–´ë–»ê²Œ ì›€ì§ì´ëŠ”ì§€(ì¤Œ/íŒ¬/í‹¸íŠ¸/ê³ ì •)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."
                    )
                    
                    camera_speed = st.selectbox(
                        "ì¹´ë©”ë¼ ì†ë„",
                        options=["very_slow", "slow", "medium", "fast"],
                        index=1,
                        format_func=lambda x: {
                            "very_slow": "ğŸŒ ë§¤ìš° ëŠë¦¼",
                            "slow": "ğŸš¶ ëŠë¦¼", 
                            "medium": "ğŸƒ ë³´í†µ",
                            "fast": "âš¡ ë¹ ë¦„"
                        }[x],
                        help="ì¹´ë©”ë¼ ì´ë™ ì†ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
                    )
                    
                    camera_angle = st.selectbox(
                        "ì¹´ë©”ë¼ ì•µê¸€",
                        options=["eye_level", "low_angle", "high_angle", "bird_eye", "worm_eye"],
                        index=0,
                        format_func=lambda x: {
                            "eye_level": "ğŸ‘ï¸ ëˆˆë†’ì´",
                            "low_angle": "ğŸ“ ë¡œìš°ì•µê¸€ (ì•„ë˜ì—ì„œ)",
                            "high_angle": "ğŸ“ í•˜ì´ì•µê¸€ (ìœ„ì—ì„œ)", 
                            "bird_eye": "ğŸ¦… ì¡°ê°ë„ (ìƒˆì˜ ì‹œì )",
                            "worm_eye": "ğŸ› ì›œë·° (ì§€ë©´ì—ì„œ)"
                        }[x],
                        help="í”¼ì‚¬ì²´ë¥¼ ì–´ë–¤ ì‹œì ì—ì„œ ì´¬ì˜í• ì§€(ëˆˆë†’ì´/ë¡œìš°/í•˜ì´/ì¡°ê°/ì›œë·°)ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
                    )

                    focal_length = st.selectbox(
                        "ë Œì¦ˆ ì´ˆì ê±°ë¦¬",
                        options=["24mm", "35mm", "50mm", "85mm"],
                        index=1,
                        help="ì´ˆì ê±°ë¦¬ê°€ ì§§ì„ìˆ˜ë¡ ê´‘ê°(ë„“ì€ í™”ê°), ê¸¸ìˆ˜ë¡ ë§ì›(ë°°ê²½ ì••ì¶•) íš¨ê³¼ê°€ ë‚©ë‹ˆë‹¤."
                    )
                
                with col_motion:
                    st.markdown("**ğŸš¶ ì¸ë¬¼ ì›€ì§ì„**")
                    
                    person_motion = st.selectbox(
                        "ì¸ë¬¼ ë™ì‘",
                        options=["none", "walking", "standing", "sitting", "running", "gesturing", "natural_micro"],
                        index=1,
                        format_func=lambda x: {
                            "none": "âŒ ì›€ì§ì„ ì—†ìŒ",
                            "walking": "ğŸš¶ ê±·ê¸°",
                            "standing": "ğŸ§ ì„œìˆê¸°",
                            "sitting": "ğŸ’º ì•‰ì•„ìˆê¸°", 
                            "running": "ğŸƒ ë›°ê¸°",
                            "gesturing": "ğŸ‘‹ ì†ì§“/ì œìŠ¤ì²˜",
                            "natural_micro": "ğŸ˜Š ìì—°ìŠ¤ëŸ¬ìš´ ë¯¸ì„¸ë™ì‘"
                        }[x],
                        help="ì£¼ìš” ì¸ë¬¼ì˜ ì›€ì§ì„ ê°•ë„/ìœ í˜•ì„ ì„ íƒí•©ë‹ˆë‹¤."
                    )
                    
                    crowd_behavior = st.selectbox(
                        "êµ°ì¤‘/ë°°ê²½ ì¸ë¬¼",
                        options=["static", "ambient", "busy", "minimal"],
                        index=1,
                        format_func=lambda x: {
                            "static": "ğŸ”’ ì •ì ",
                            "ambient": "ğŸŒŠ ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„",
                            "busy": "ğŸƒâ€â™‚ï¸ í™œë°œí•œ ì›€ì§ì„",
                            "minimal": "ğŸ˜´ ìµœì†Œí•œì˜ ì›€ì§ì„"
                        }[x],
                        help="ë°°ê²½ ì¸ë¬¼ì˜ ì „ë°˜ì ì¸ ì›€ì§ì„ ë°€ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
                    )
                    
                    interaction = st.selectbox(
                        "ì¸ë¬¼ ìƒí˜¸ì‘ìš©",
                        options=["none", "looking_around", "pointing", "talking", "enjoying"],
                        index=4,
                        format_func=lambda x: {
                            "none": "âŒ ìƒí˜¸ì‘ìš© ì—†ìŒ",
                            "looking_around": "ğŸ‘€ ì£¼ë³€ ë‘˜ëŸ¬ë³´ê¸°",
                            "pointing": "ğŸ‘‰ ê°€ë¦¬í‚¤ê¸°",
                            "talking": "ğŸ’¬ ëŒ€í™”í•˜ê¸°", 
                            "enjoying": "ğŸ˜Š ì¦ê¸°ëŠ” ëª¨ìŠµ"
                        }[x],
                        help="ì¸ë¬¼ì´ ë¬´ì—‡ì„ í•˜ëŠ”ì§€(ë‘˜ëŸ¬ë³´ê¸°/ê°€ë¦¬í‚¤ê¸°/ëŒ€í™”/ê°ìƒ)ë¥¼ ì§€ì •í•©ë‹ˆë‹¤."
                    )

                    motion_blur = st.slider(
                        "ëª¨ì…˜ ë¸”ëŸ¬ ê°•ë„",
                        min_value=0.0,
                        max_value=1.0,
                        value=0.2,
                        step=0.05,
                        help="ì›€ì§ì„ì— ë”°ë¥¸ ì”ìƒ(ëª¨ì…˜ ë¸”ëŸ¬) ì •ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤."
                    )

                    stabilization = st.checkbox("ì˜ìƒ í”ë“¤ë¦¼ ë³´ì •", value=True, help="ì¹´ë©”ë¼ í”ë“¤ë¦¼ì„ ì¤„ì´ê¸° ìœ„í•œ ì•ˆì •í™” íš¨ê³¼ë¥¼ ì ìš©í•©ë‹ˆë‹¤.")
                
                with col_style:
                    st.markdown("**ğŸŒŸ í™˜ê²½ íš¨ê³¼**")
                    
                    environmental_motion = st.multiselect(
                        "í™˜ê²½ ì›€ì§ì„",
                        options=["wind", "water", "clouds", "leaves", "flags", "smoke", "sparkles", "birds"],
                        default=["wind", "clouds"],
                        format_func=lambda x: {
                            "wind": "ğŸ’¨ ë°”ëŒ íš¨ê³¼",
                            "water": "ğŸŒŠ ë¬¼ ì›€ì§ì„",
                            "clouds": "â˜ï¸ êµ¬ë¦„ ì´ë™",
                            "leaves": "ğŸƒ ë‚˜ë­‡ì í”ë“¤ë¦¼",
                            "flags": "ğŸš© ê¹ƒë°œ í„ëŸ­ì„", 
                            "smoke": "ğŸ’¨ ì—°ê¸°/ì•ˆê°œ",
                            "sparkles": "âœ¨ ë°˜ì§ì„ íš¨ê³¼",
                            "birds": "ğŸ¦ ìƒˆ ë‚ ì•„ë‹¤ë‹˜"
                        }[x],
                        help="ì¥ë©´ì— ìì—°ìŠ¤ëŸ¬ìš´ í™˜ê²½ ì›€ì§ì„(ë°”ëŒ/ë¬¼/êµ¬ë¦„ ë“±)ì„ ì¶”ê°€í•©ë‹ˆë‹¤."
                    )
                    
                    lighting_mood = st.selectbox(
                        "ì¡°ëª… ë¶„ìœ„ê¸°",
                        options=["natural", "golden_hour", "blue_hour", "dramatic", "soft", "bright"],
                        index=0,
                        format_func=lambda x: {
                            "natural": "â˜€ï¸ ìì—°ê´‘",
                            "golden_hour": "ğŸŒ… ê³¨ë“ ì•„ì›Œ",
                            "blue_hour": "ğŸŒ† ë¸”ë£¨ì•„ì›Œ",
                            "dramatic": "ğŸ­ ë“œë¼ë§ˆí‹±",
                            "soft": "ğŸ’¡ ë¶€ë“œëŸ¬ìš´ ì¡°ëª…",
                            "bright": "ğŸ’¡ ë°ì€ ì¡°ëª…"
                        }[x],
                        help="ì¥ë©´ì˜ ì „ë°˜ì ì¸ ì¡°ëª… ë¶„ìœ„ê¸°ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."
                    )
                    
                    video_style = st.selectbox(
                        "ì˜ìƒ ìŠ¤íƒ€ì¼",
                        options=["cinematic", "documentary", "commercial", "artistic", "travel_vlog", "instagram"],
                        index=0,
                        format_func=lambda x: {
                            "cinematic": "ğŸ¬ ì˜í™”ì ",
                            "documentary": "ğŸ“º ë‹¤íë©˜í„°ë¦¬",
                            "commercial": "ğŸ“º ê´‘ê³ ìš©",
                            "artistic": "ğŸ¨ ì˜ˆìˆ ì ",
                            "travel_vlog": "âœˆï¸ ì—¬í–‰ ë¸Œì´ë¡œê·¸",
                            "instagram": "ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨"
                        }[x],
                        help="ì—°ì¶œ í†¤ê³¼ í¸ì§‘ ê°ì„±(ì˜í™”ì /ë‹¤í/ê´‘ê³  ë“±)ì„ ì„¤ì •í•©ë‹ˆë‹¤."
                    )

                    color_grade = st.selectbox(
                        "ì»¬ëŸ¬ ê·¸ë ˆì´ë”©",
                        options=["natural", "teal_orange", "warm", "cool", "black_white", "high_contrast"],
                        index=0,
                        format_func=lambda x: {
                            "natural": "ğŸŒˆ ë‚´ì¶”ëŸ´",
                            "teal_orange": "ğŸŸ¦ğŸŸ§ í‹¸&ì˜¤ë Œì§€",
                            "warm": "ğŸ”¥ ì›œí†¤",
                            "cool": "â„ï¸ ì¿¨í†¤",
                            "black_white": "âš«âšª í‘ë°±",
                            "high_contrast": "ğŸŒ“ í•˜ì´ ì½˜íŠ¸ë¼ìŠ¤íŠ¸"
                        }[x],
                        help="ìƒ‰ê° í†¤ì„ ì§€ì •í•©ë‹ˆë‹¤(ë‚´ì¶”ëŸ´/í‹¸&ì˜¤ë Œì§€/ì›œ/ì¿¨/í‘ë°±/í•˜ì´ ì½˜íŠ¸ë¼ìŠ¤íŠ¸)."
                    )

                    film_grain = st.slider("í•„ë¦„ ê·¸ë ˆì¸", 0.0, 1.0, 0.0, 0.05, help="í•„ë¦„ ì§ˆê°ì˜ ì…ìê°ì„ ì¶”ê°€í•©ë‹ˆë‹¤.")
                    vignette = st.slider("ë¹„ë„¤íŠ¸ ê°•ë„", 0.0, 1.0, 0.0, 0.05, help="í”„ë ˆì„ ê°€ì¥ìë¦¬ë¥¼ ì–´ë‘¡ê²Œ í•´ ì‹œì„ ì„ ì¤‘ì•™ìœ¼ë¡œ ëª¨ìë‹ˆë‹¤.")
                    depth_of_field = st.checkbox("í”¼ì‚¬ê³„ ì‹¬ë„(ë°°ê²½ íë¦¼)", value=False, help="í”¼ì‚¬ì²´ëŠ” ë˜ë ·í•˜ê²Œ, ë°°ê²½ì€ íë¦¿í•˜ê²Œ ë§Œë“¤ì–´ ì…ì²´ê°ì„ ì¤ë‹ˆë‹¤.")
                    bokeh_strength = 0.0
                    if depth_of_field:
                        bokeh_strength = st.slider("ë³´ì¼€ ê°•ë„", 0.0, 1.0, 0.4, 0.05, help="ë¹›ë§ìš¸(ë³´ì¼€)ì˜ í¬ê¸°/ê°•ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.")
                    
                # ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±
                def generate_custom_prompt():
                    """ì‚¬ìš©ì ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„± (ë¦¬ì–¼ë¦¬ì¦˜ ê°•í™”)"""
                    base_prompt = (
                        "Create a realistic, natural-looking 9:16 travel video from this image. "
                        "Emphasize photorealism and subtlety."
                    )
                    
                    # ì¹´ë©”ë¼ ì›€ì§ì„
                    camera_descriptions = {
                        "push_in": "Add a slow push-in camera movement",
                        "pull_out": "Add a pull-out camera movement revealing more of the scene",
                        "pan_left": "Add a smooth left panning movement",
                        "pan_right": "Add a smooth right panning movement", 
                        "tilt_up": "Add an upward tilting movement",
                        "tilt_down": "Add a downward tilting movement",
                        "static": "Keep the camera static with no movement",
                        "orbit": "Add a subtle orbital camera movement around the subject"
                    }
                    
                    camera_speeds = {
                        "very_slow": "very slowly",
                        "slow": "slowly", 
                        "medium": "at medium speed",
                        "fast": "quickly"
                    }
                    
                    camera_angles = {
                        "eye_level": "from eye level",
                        "low_angle": "from a low angle looking up",
                        "high_angle": "from a high angle looking down",
                        "bird_eye": "from a bird's eye view",
                        "worm_eye": "from ground level looking up"
                    }
                    
                    # ì¸ë¬¼ ë™ì‘
                    person_descriptions = {
                        "none": "Keep people completely still",
                        "walking": "Show people walking naturally",
                        "standing": "Show people standing with subtle movements",
                        "sitting": "Show people sitting comfortably",
                        "running": "Show people running or jogging",
                        "gesturing": "Show people making natural gestures",
                        "natural_micro": "Add natural micro-movements like breathing and small gestures"
                    }
                    
                    crowd_descriptions = {
                        "static": "Keep background people completely still",
                        "ambient": "Add natural ambient movement to background people",
                        "busy": "Show busy, active background movement", 
                        "minimal": "Add minimal, subtle background movement"
                    }
                    
                    # í™˜ê²½ íš¨ê³¼
                    env_descriptions = {
                        "wind": "gentle breeze moving elements",
                        "water": "water movement and ripples",
                        "clouds": "slow-moving clouds",
                        "leaves": "leaves rustling in the wind",
                        "flags": "flags waving gently",
                        "smoke": "subtle smoke or mist effects",
                        "sparkles": "magical sparkle effects",
                        "birds": "birds flying in the background"
                    }
                    
                    # ì¡°ëª… ë¶„ìœ„ê¸°
                    lighting_descriptions = {
                        "natural": "with natural lighting",
                        "golden_hour": "with warm golden hour lighting",
                        "blue_hour": "with cool blue hour lighting",
                        "dramatic": "with dramatic lighting and shadows",
                        "soft": "with soft, diffused lighting",
                        "bright": "with bright, vibrant lighting"
                    }
                    
                    # ì˜ìƒ ìŠ¤íƒ€ì¼
                    style_descriptions = {
                        "cinematic": "Cinematic style with professional composition",
                        "documentary": "Documentary style with natural, realistic feel",
                        "commercial": "Commercial style with polished, marketing appeal",
                        "artistic": "Artistic style with creative composition",
                        "travel_vlog": "Travel vlog style with engaging, personal feel", 
                        "instagram": "Instagram-ready style with social media appeal"
                    }
                    
                    # í”„ë¡¬í”„íŠ¸ ì¡°í•©
                    prompt_parts = [base_prompt]
                    
                    # ì¹´ë©”ë¼ ì„¤ì •
                    if camera_movement != "static":
                        camera_desc = f"{camera_descriptions[camera_movement]} {camera_speeds[camera_speed]} {camera_angles[camera_angle]}"
                        prompt_parts.append(camera_desc)
                    
                    # ì¸ë¬¼ ì›€ì§ì„
                    if person_motion != "none":
                        prompt_parts.append(person_descriptions[person_motion])
                    
                    prompt_parts.append(crowd_descriptions[crowd_behavior])
                    
                    # í™˜ê²½ íš¨ê³¼
                    if environmental_motion:
                        env_effects = [env_descriptions[env] for env in environmental_motion]
                        prompt_parts.append(f"Include {', '.join(env_effects)}")
                    
                    # ì¡°ëª…ê³¼ ìŠ¤íƒ€ì¼
                    prompt_parts.append(f"{style_descriptions[video_style]} {lighting_descriptions[lighting_mood]}")
                    
                    # ë Œì¦ˆ/ì•ˆì •í™”/ëª¨ì…˜ ë¸”ëŸ¬
                    prompt_parts.append(f"Use a {focal_length} lens")
                    if stabilization:
                        prompt_parts.append("Apply stabilization to reduce shake")
                    if motion_blur > 0:
                        prompt_parts.append("Include natural motion blur appropriate to movement")

                    # ì»¬ëŸ¬/ê·¸ë ˆì¸/ë¹„ë„¤íŠ¸/DOF
                    grade_texts = {
                        "natural": "with natural color grading",
                        "teal_orange": "with teal and orange color grading",
                        "warm": "with warm color tones",
                        "cool": "with cool color tones",
                        "black_white": "in black and white",
                        "high_contrast": "with high contrast color grading",
                    }
                    prompt_parts.append(grade_texts.get(color_grade, "with natural color grading"))
                    if film_grain > 0:
                        prompt_parts.append("add subtle film grain")
                    if vignette > 0:
                        prompt_parts.append("apply subtle vignette")
                    if depth_of_field:
                        prompt_parts.append("shallow depth of field with pleasing bokeh")
                    
                    # ê¸°ë³¸ í’ˆì§ˆ/ë¦¬ì–¼ë¦¬ì¦˜ ì„¤ì •
                    prompt_parts.append(
                        "Maintain the original colors and atmosphere. Vertical format, high quality."
                    )
                    # ê³ ì • ì¢…íš¡ë¹„(9:16) ê°•ì œ ë° í”„ë ˆì´ë° ê°€ì´ë“œ
                    prompt_parts.append(
                        "Final output must be strictly 9:16 (1080x1920). If the source is not 9:16, perform a smart center-crop "
                        "or minimal padding to preserve composition; never stretch or squash the image."
                    )
                    # ë¦¬ì–¼ë¦¬ì¦˜/ê¸ˆì§€ ì‚¬í•­ (AI ëŠë‚Œ ìµœì†Œí™”)
                    prompt_parts.append(
                        "Photorealistic output. Avoid AI-like artifacts, oversaturation, over-sharpening, waxy skin, "
                        "flicker, jitter, warping, extra fingers/limbs, melting textures, or unintended text/logos."
                    )
                    prompt_parts.append(
                        "Preserve subject identity and geometry; do not add or remove objects, people, or change the scene layout."
                    )
                    prompt_parts.append(
                        "Keep motion subtle and physically plausible; no abrupt or surreal movements."
                    )
                    
                    return ". ".join(prompt_parts) + "."
                
                # ì‹¤ì‹œê°„ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
                custom_prompt = generate_custom_prompt()
                
                # í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°
                st.markdown("### ğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
                with st.expander("ğŸ” ìë™ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸", expanded=True):
                    st.text_area(
                        "í˜„ì¬ ì„¤ì •ìœ¼ë¡œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸",
                        value=custom_prompt,
                        height=100,
                        help="ìœ„ì˜ ì„¤ì •ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìë™ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •í•˜ë ¤ë©´ ìœ„ì˜ í”„ë¡¬í”„íŠ¸ ì…ë ¥ì°½ì„ ì‚¬ìš©í•˜ì„¸ìš”."
                    )
                    
                    if st.button("ğŸ“‹ í”„ë¡¬í”„íŠ¸ ë³µì‚¬", help="ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„ì˜ ì…ë ¥ì°½ì— ë³µì‚¬"):
                        st.session_state.custom_prompt = custom_prompt
                        st.success("âœ… í”„ë¡¬í”„íŠ¸ê°€ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤! ìœ„ì˜ í”„ë¡¬í”„íŠ¸ ì…ë ¥ì°½ì„ í™•ì¸í•˜ì„¸ìš”.")
                
                # ì„¤ì • ìš”ì•½
                st.markdown("### ğŸ“Š í˜„ì¬ ì„¤ì • ìš”ì•½")
                
                col_summary1, col_summary2, col_summary3 = st.columns(3)
                
                with col_summary1:
                    st.markdown("**ğŸ“¹ ì¹´ë©”ë¼**")
                    st.info(f"""
                    **ë™ì‘:** {camera_movement.replace('_', ' ').title()}
                    **ì†ë„:** {camera_speed.replace('_', ' ').title()}
                    **ì•µê¸€:** {camera_angle.replace('_', ' ').title()}
                    """)
                
                with col_summary2:
                    st.markdown("**ğŸš¶ ì¸ë¬¼**")
                    st.info(f"""
                    **ì£¼ì¸ë¬¼:** {person_motion.replace('_', ' ').title()}
                    **ë°°ê²½ì¸ë¬¼:** {crowd_behavior.replace('_', ' ').title()}
                    **ìƒí˜¸ì‘ìš©:** {interaction.replace('_', ' ').title()}
                    """)
                
                with col_summary3:
                    st.markdown("**ğŸŒŸ í™˜ê²½**")
                    env_text = ", ".join([env.replace('_', ' ').title() for env in environmental_motion]) if environmental_motion else "ì—†ìŒ"
                    st.info(f"""
                    **í™˜ê²½íš¨ê³¼:** {env_text}
                    **ì¡°ëª…:** {lighting_mood.replace('_', ' ').title()}
                    **ìŠ¤íƒ€ì¼:** {video_style.replace('_', ' ').title()}
                    """)
                
                # ì €ì¥í•  ì„¤ì •ë“¤ (ì—…ë°ì´íŠ¸)
                # í…ìŠ¤íŠ¸ ê¸°ëŠ¥ ë¹„í™œì„±í™”ì— ë”°ë¼ ë¹ˆ ì„¤ì • ì €ì¥
                st.session_state.text_settings = {}
                
                # í”„ë¡¬í”„íŠ¸ ì„ íƒ (ìˆ˜ë™ vs ìë™)
                use_custom_prompt = st.session_state.get('custom_prompt') == custom_prompt
                final_prompt = st.session_state.get('custom_prompt', custom_prompt) if use_custom_prompt else prompt_template
                
                # AI ì—”ì§„ë³„ ì„¤ì • ì €ì¥
                video_settings = {
                    'ai_engine': ai_engine,
                    'prompt': final_prompt,
                    'camera_movement': camera_movement,
                    'camera_speed': camera_speed,
                    'camera_angle': camera_angle,
                    'focal_length': focal_length,
                    'person_motion': person_motion,
                    'crowd_behavior': crowd_behavior,
                    'interaction': interaction,
                    'motion_blur': motion_blur,
                    'stabilization': stabilization,
                    'environmental_motion': environmental_motion,
                    'lighting_mood': lighting_mood,
                    'video_style': video_style,
                    'color_grade': color_grade,
                    'film_grain': film_grain,
                    'vignette': vignette,
                    'depth_of_field': depth_of_field,
                    'bokeh_strength': bokeh_strength,
                    'custom_prompt': custom_prompt
                }
                
                if ai_engine == "higgs":
                    # Higgs ëª¨ì…˜ ëª©ë¡ ì¡°íšŒ ë° ì„ íƒê°’ì„ idë¡œ ë§¤í•‘
                    motions = get_higgs_motions()
                    motion_name_to_id = {m.get('name'): m.get('id') for m in motions if m.get('name') and m.get('id')}
                    selected_names = locals().get('higgs_motions', [])
                    selected_motion_ids = [motion_name_to_id.get(n, n) for n in selected_names]

                    video_settings.update({
                        'higgs_model': locals().get('higgs_model', 'higgs-video-1'),
                        'higgs_motions': selected_motion_ids,
                        'higgs_style': locals().get('higgs_style', 'cinematic'),
                        'ratio': locals().get('higgs_ratio', '1080:1920'),
                        'duration': locals().get('video_duration', 5),
                        'motion_strength': locals().get('motion_strength', 0.5)
                    })
                
                st.session_state.video_settings = video_settings

                # ğŸ§² HiggsField ê²°ê³¼ ì¡°íšŒ(ë“œë¼ì´ëŸ°): job_set_idë¡œ ê²°ê³¼ë§Œ í™•ì¸
                with st.expander("ğŸ§² HiggsField ê²°ê³¼ ì¡°íšŒ(ë“œë¼ì´ëŸ°)", expanded=False):
                    job_set_id = st.text_input("Job Set ID", value="", help="Higgsfieldì—ì„œ ìƒì„±ëœ job_set_idë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                    if st.button("ì¡°íšŒ", key="btn_higgs_poll"):
                        try:
                            from src.generators.higgs.video import HiggsVideoGenerator
                            gen = HiggsVideoGenerator(output_dir=Path("outputs"))
                            data = gen.get_job_set(job_set_id)
                            st.json(data)

                            # ê²°ê³¼ URL ì¶”ì¶œ
                            video_url = None
                            try:
                                for job in data.get("jobs", []):
                                    results = job.get("results") or {}
                                    for key in ("raw", "min"):
                                        obj = results.get(key) or {}
                                        u = obj.get("url")
                                        if isinstance(u, str) and u.startswith("http"):
                                            video_url = u
                                            break
                                    if video_url:
                                        break
                            except Exception:
                                pass

                            if video_url:
                                st.video(video_url)
                            else:
                                st.info("ê²°ê³¼ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ì—… ìƒíƒœê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                        except Exception as e:
                            st.error(f"Higgs ì¡°íšŒ ì˜¤ë¥˜: {e}")
                    
                # 5ë‹¨ê³„: ì˜ìƒ ìƒì„± ì‹¤í–‰
                if st.button("ğŸš€ ì˜ìƒ ìƒì„± ì‹œì‘", type="primary", width="stretch"):
                    # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                    text_settings = st.session_state.get('text_settings', {})
                    video_settings = st.session_state.get('video_settings', {})
                    logger.info("Video generation triggered. engine=%s dry_run=%s", video_settings.get('ai_engine'), st.session_state.get('dry_run_flow', 'unknown'))
                    
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    progress_container = st.container()
                    status_text = st.empty()
                    
                    try:
                        # í•„ìš”í•œ ëª¨ë“ˆ import
                        import tempfile
                        import os
                        
                        # ì´ë¯¸ì§€ ì¤€ë¹„
                        status_text.info("ğŸ“¸ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì¤‘...")
                        
                        # ë¦¬ì‚¬ì´ì¦ˆ
                        resized_img = create_resized_preview(selected['image'])
                        
                        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
                            # ì„ íƒëœ ì†ŒìŠ¤ì— ë”°ë¼ ì €ì¥
                            if image_source == "original":
                                source_img = selected['image']
                            else:
                                source_img = resized_img
                            source_img.save(tmp_file.name, quality=92)
                            tmp_jpg = tmp_file.name
                            
                            # AI ì—”ì§„ ì„ íƒ
                            ai_engine = video_settings.get('ai_engine', 'gemini_veo')
                            prompt = video_settings.get('prompt', prompt_template)
                            
                            if dry_run_flow:
                                status_text.info("ğŸ§ª ë“œë¼ì´ëŸ°: ë¡œì»¬ ì‹œë®¬ë ˆì´ì…˜ ì˜ìƒ ìƒì„± ì¤‘ (í¬ë ˆë”§ ì†Œì§„ ì—†ìŒ)...")
                                sim_out = f"outputs/sim_{int(time.time())}.mp4"
                                os.makedirs("outputs", exist_ok=True)
                                logger.info("Generating local simulation video. out=%s", sim_out)
                                result_path = generate_local_simulation_video(resized_img, sim_out, duration=6, fps=30)
                                if os.path.exists(result_path):
                                    status_text.success("âœ… ë“œë¼ì´ëŸ° ì™„ë£Œ!")
                                    with open(result_path, 'rb') as f:
                                        vb = f.read()
                                        st.video(vb)
                                        st.download_button("ğŸ“¥ ì‹œë®¬ë ˆì´ì…˜ ì˜ìƒ ë‹¤ìš´ë¡œë“œ", vb, file_name="simulation.mp4", mime="video/mp4")
                                else:
                                    status_text.error("âŒ ë“œë¼ì´ëŸ° ì˜ìƒ ìƒì„± ì‹¤íŒ¨")
                                return
                            
                            if ai_engine == "runway_ai":
                                status_text.info("ğŸš€ Runway AI ì„¤ì • í™•ì¸ ì¤‘...")
                                logger.info("Runway AI flow started")
                                
                                # Runway AI API í‚¤ í™•ì¸
                                api_key = os.getenv("RUNWAY_API_KEY")
                                if not api_key:
                                    st.error("âŒ RUNWAY_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                                    st.info("ğŸ’¡ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ì„¸ìš”:")
                                    st.code(f'export RUNWAY_API_KEY="runway-api-key"')
                                    return
                                
                                # API ì—°ê²° í…ŒìŠ¤íŠ¸
                                import requests
                                headers = {
                                    'Authorization': f'Bearer {api_key}',
                                    'Content-Type': 'application/json',
                                    'X-Runway-Version': '2024-11-06'
                                }
                                
                                try:
                                    response = requests.get("https://api.dev.runwayml.com/v1/organization", 
                                                          headers=headers, timeout=10)
                                    
                                    if response.status_code == 200:
                                        org_info = response.json()
                                        credit_balance = org_info.get('creditBalance', 0)
                                        
                                        if credit_balance <= 0:
                                            st.warning("âš ï¸ Runway AI í¬ë ˆë”§ ì”ì•¡ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                                            st.info("ğŸ’³ í¬ë ˆë”§ì„ ì¶©ì „í•˜ë ¤ë©´ [Runway ML](https://runwayml.com) ì›¹ì‚¬ì´íŠ¸ë¥¼ ë°©ë¬¸í•˜ì„¸ìš”.")
                                            st.json(org_info)
                                            return
                                        else:
                                            st.success(f"âœ… Runway AI ì—°ê²° ì„±ê³µ! í¬ë ˆë”§ ì”ì•¡: {credit_balance}")
                                    else:
                                        st.error(f"âŒ Runway API ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
                                        st.text(response.text)
                                        return
                                        
                                except Exception as e:
                                    st.error(f"âŒ Runway API ì—°ê²° ì˜¤ë¥˜: {e}")
                                    return
                                
                                # ì‹¤ì œ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘
                                status_text.info("ğŸš€ Runway AIë¡œ ì˜ìƒ ìƒì„± ì¤‘...")
                                
                                try:
                                    # í•„ìš”í•œ ëª¨ë“ˆë“¤ import
                                    import tempfile
                                    import os
                                    import requests
                                    from src.generators.runway.video import RunwayVideoGenerator
                                    
                                    runway_generator = RunwayVideoGenerator()
                                    
                                    # ì„ì‹œ íŒŒì¼ë¡œ ì´ë¯¸ì§€ ì €ì¥ (ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ì‚¬ìš©)
                                    tmp_image_path = None
                                    try:
                                        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                                            # ì„ íƒëœ ì´ë¯¸ì§€ë¥¼ 1080x1920ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                                            selected_img = st.session_state.selected_image['image']
                                            resized_img = create_resized_preview(selected_img)
                                            
                                            # ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
                                            img_bytes = io.BytesIO()
                                            resized_img.save(img_bytes, format='JPEG', quality=95)
                                            img_bytes.seek(0)
                                            tmp_file.write(img_bytes.getvalue())
                                            
                                            tmp_image_path = tmp_file.name
                                    except Exception as img_error:
                                        st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {img_error}")
                                        return
                                    
                                    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
                                    output_path = f"outputs/runway_video_{int(time.time())}.mp4"
                                    os.makedirs("outputs", exist_ok=True)
                                    
                                    # ë¹„ë””ì˜¤ ìƒì„± (ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©)
                                    selected_model = video_settings.get('runway_model', 'gen3a_turbo')
                                    selected_ratio = video_settings.get('ratio')
                                    dry_run = bool(video_settings.get('dry_run', True))
                                    force_live = not dry_run
                                    logger.info("Runway request: model=%s ratio=%s dry_run=%s", selected_model, selected_ratio, dry_run)
                                    result_path = runway_generator.generate_video_from_image(
                                        image_path=tmp_image_path,
                                        output_path=output_path,
                                        duration=8,  # 8ì´ˆ ê³ ì •
                                        prompt=prompt if prompt else "A beautiful video with natural motion",
                                        model=selected_model,
                                        ratio=selected_ratio,
                                        dry_run=dry_run,
                                        force_live=force_live
                                    )
                                    
                                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                                    if tmp_image_path and os.path.exists(tmp_image_path):
                                        os.unlink(tmp_image_path)
                                    
                                    if os.path.exists(result_path):
                                        logger.info("Runway video generated at %s", result_path)
                                        status_text.success("âœ… Runway AI ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
                                        st.success(f"ğŸ¬ ë¹„ë””ì˜¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {result_path}")
                                        
                                        # ë¹„ë””ì˜¤ íŒŒì¼ í‘œì‹œ
                                        with open(result_path, 'rb') as video_file:
                                            video_bytes = video_file.read()
                                            st.video(video_bytes)
                                        
                                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                                        st.download_button(
                                            label="ğŸ“¥ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
                                            data=video_bytes,
                                            file_name=f"runway_video_{int(time.time())}.mp4",
                                            mime="video/mp4"
                                        )

                                        # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì ìš© (ì˜µì…˜)
                                        # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ë¹„í™œì„±í™”: ì›ë³¸ ì˜ìƒë§Œ ì œê³µ
                                    else:
                                        logger.error("Runway video not found at %s", result_path)
                                        status_text.error("âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
                                        
                                except Exception as e:
                                    logger.exception("Runway flow error: %s", e)
                                    status_text.error(f"âŒ Runway AI ì˜¤ë¥˜: {e}")
                                    st.error(f"ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
                                    
                                return
                                
                                # Runway AIëŠ” ì—¬ê¸°ì„œ ì™„ë£Œ, returnìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì½”ë“œ ìŠ¤í‚µ
                                safe_unlink(tmp_jpg)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ(ì¬ì‹œë„)
                                return
                            
                            # ê¸°íƒ€ ì—”ì§„ ê³„ì† (Veo ê²½ë¡œëŠ” ë¹„í™œì„±í™”ë˜ì–´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                            
                            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                            safe_unlink(tmp_jpg)

                            # HiggsField ë¶„ê¸° ì²˜ë¦¬ (ì‹¤ì œ ìƒì„± â†’ í´ë§)
                            if ai_engine == "higgs":
                                status_text.info("ğŸ§² HiggsFieldë¡œ ì˜ìƒ ìƒì„± ìš”ì²­ ì¤‘...")
                                try:
                                    import requests
                                    # UI ì…ë ¥ê°’ ìš°ì„ , ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
                                    api_key = (st.session_state.get("HIGGS_API_KEY", "") or os.getenv("HIGGS_API_KEY", "")).strip()
                                    api_secret = (st.session_state.get("HIGGS_SECRET", "") or os.getenv("HIGGS_SECRET", "")).strip()
                                    if not api_key or not api_secret:
                                        st.error("âŒ HIGGS_API_KEY/HIGGS_SECRET í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                                        return

                                    # ì…ë ¥ ì´ë¯¸ì§€: ì„ íƒ í•­ëª©ì—ì„œ ì›ë³¸ URL ìë™ í•´ì„
                                    img_url = resolve_image_url(selected)
                                    if not isinstance(img_url, str) or not img_url.startswith("http"):
                                        st.error("âŒ ì„ íƒí•œ ì´ë¯¸ì§€ì˜ ì›ë³¸ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                        return

                                    # ëª¨ì…˜ idì™€ ê°•ë„ êµ¬ì„±
                                    sel_motion_ids = video_settings.get('higgs_motions', []) or []
                                    strength = float(video_settings.get('motion_strength', 0.5))
                                    motions_payload = [{"id": mid, "strength": strength} for mid in sel_motion_ids]

                                    # ëª¨ë¸/í”„ë¡¬í”„íŠ¸/ì‹œë“œ
                                    model = video_settings.get('higgs_model', 'dop-turbo')
                                    seed_val = st.session_state.get('seed_value') if 'seed_value' in st.session_state else None

                                    payload = {
                                        "webhook": None,
                                        "params": {
                                            "model": model,
                                            "prompt": prompt,
                                            "seed": int(seed_val) if isinstance(seed_val, int) else 500000,
                                            "motions": motions_payload,
                                            "input_images": [
                                                {"type": "image_url", "image_url": img_url}
                                            ],
                                            "enhance_prompt": True
                                        }
                                    }

                                    headers = {
                                        "Content-Type": "application/json",
                                        "hf-api-key": api_key,
                                        "hf-secret": api_secret
                                    }

                                    resp = requests.post(
                                        "https://platform.higgsfield.ai/v1/image2video/dop",
                                        headers=headers,
                                        json=payload,
                                        timeout=30
                                    )
                                    if resp.status_code >= 400:
                                        st.error(f"âŒ Higgs ìƒì„± ì‹¤íŒ¨: {resp.status_code}\n{resp.text}")
                                        return
                                    job = resp.json()
                                    job_set_id = job.get("id")
                                    if not job_set_id:
                                        st.error("âŒ Higgs ì‘ë‹µì— id(job_set_id)ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                        st.json(job)
                                        return

                                    status_text.info(f"â³ ìƒì„± ì§„í–‰ ì¤‘ (job_set_id={job_set_id}) â€¦")
                                    # í´ë§
                                    start_ts = time.time()
                                    video_url = None
                                    while time.time() - start_ts < 600:
                                        try:
                                            res = requests.get(
                                                f"https://platform.higgsfield.ai/v1/job-sets/{job_set_id}",
                                                headers={"hf-api-key": api_key, "hf-secret": api_secret},
                                                timeout=15
                                            )
                                            if res.status_code == 200:
                                                data = res.json()
                                                # ê²°ê³¼ URL ì¶”ì¶œ
                                                jobs = data.get("jobs", [])
                                                for j in jobs:
                                                    if str(j.get("status", "")).lower() == "completed":
                                                        results = j.get("results") or {}
                                                        for k in ("raw", "min"):
                                                            obj = results.get(k) or {}
                                                            u = obj.get("url")
                                                            if isinstance(u, str) and u.startswith("http"):
                                                                video_url = u
                                                                break
                                                    if video_url:
                                                        break
                                                if video_url:
                                                    break
                                            elif res.status_code == 422:
                                                pass
                                        except Exception:
                                            pass
                                        time.sleep(4)
                                        waited = int(time.time() - start_ts)
                                        status_text.info(f"â³ ìƒì„± ëŒ€ê¸° ì¤‘â€¦ {waited}s")

                                    if not video_url:
                                        st.warning("âš ï¸ ì œí•œ ì‹œê°„ ë‚´ ê²°ê³¼ URLì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. job_set_idë¡œ ìˆ˜ë™ ì¡°íšŒí•´ ì£¼ì„¸ìš”.")
                                        st.code(job_set_id)
                                        return

                                    status_text.success("âœ… HiggsField ì˜ìƒ ìƒì„± ì™„ë£Œ!")
                                    st.video(video_url)
                                    st.download_button("ğŸ“¥ ì˜ìƒ URL ë³µì‚¬", data=video_url, file_name="video_url.txt")
                                    return
                                except Exception as e:
                                    status_text.error(f"âŒ HiggsField ì˜¤ë¥˜: {e}")
                                    return
                    
                    except Exception as e:
                        status_text.error(f"âŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {e}")
                        st.error("ğŸ”„ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ë³´ì„¸ìš”.")
    
    else:
        st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ ìƒí’ˆ IDë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì˜ˆì‹œ ìƒí’ˆì„ ì„ íƒí•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
